#!/usr/bin/env python

import argparse
import glob
import os
import sys
import dask.dataframe as ddf
from cloudpickle import dumps
from random import randint

from dask_ml.preprocessing import MinMaxScaler

prefix = "/opt/ml"

labels = ['adware', 'flooder', 'ransomware', 'dropper', 'spyware', 'packed',
          'crypto_miner', 'file_infector', 'installer', 'worm', 'downloader']
features = [f"feature_{x}" for x in range(2381)]


def log_container_info(prefix):
    print('------------------- environment variables -------------------')
    print(os.environ)
    print('------------------- environment variables -------------------')
    print('------------------- arguments -------------------')
    print(sys.argv)
    print('------------------- arguments -------------------')
    print('------------------- filesystem -------------------')
    for filename in glob.iglob(prefix + '**/**', recursive=True):
        print(filename)
    print('------------------- filesystem -------------------')


def process(args):
    print('Starting the processing.')

    df = ddf.read_parquet(
        f"{prefix}/processing/data/", compression="snappy", columns=(features+labels))
    

    train, test, val = df.random_split([0.7, 0.2, 0.1], random_state=args.random_state, shuffle=True)

    print("scale x train/test/val")
    scaler = MinMaxScaler()
    scaler.fit(train[features])

    features_train, features_test, features_val = scaler.transform(train[features]), scaler.transform(test[features]), scaler.transform(val[features])

    train, test, val = train.drop(features, axis=1), test.drop(features, axis=1), val.drop(features, axis=1)
    train, test, val = train.join(features_train), test.join(features_test), val.join(features_val)
    

    print("save train, test and val")
    train.to_parquet(
        f"{prefix}/processing/output/{args.train_name}/", compression="snappy", compute=True)
    test.to_parquet(
        f"{prefix}/processing/output/{args.test_name}/", compression="snappy", compute=True)
    val.to_parquet(
        f"{prefix}/processing/output/{args.val_name}/", compression="snappy", compute=True)

    print("save scaler")
    filename = f"{prefix}/processing/output/scaler/scaler.pkl"
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    with open(filename, "wb") as f:
        f.write(dumps(scaler))

    print('Finish the processing.')


if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument("-train-name", type=str, default="train")
    parser.add_argument("-test-name", type=str, default="test")
    parser.add_argument("-val-name", type=str, default="val")
    parser.add_argument("-random-state", type=int, default=randint(0, 2**32))
    args = parser.parse_args()

    log_container_info(prefix)
    process(args)

    sys.exit(0)
